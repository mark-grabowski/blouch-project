---
title: "Blouch Example Cervid Analysis - Example"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---


```{r}
rm(list=ls())
# Load necessary packages
library(ape)
library(slouch)
library(rstan)
library(treeplyr)

#For execution on a local, multicore CPU with excess RAM we recommend calling
#options(mc.cores = parallel::detectCores())
options(mc.cores = 2)
rstan_options(auto_write = TRUE)

#remotes::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")

```
For the purposes of illustrating the software, we will use a dataset of ruminant neocortices bundled with the package and a corresponding phylogenetic tree (ToljagiÄ‡ et al. 2017). First, we will organize the neocortex data and associated annotation data.
```{r}
## Load the phylogenetic tree with annotation data
data(artiodactyla)
phy <- artiodactyla

## Load the neocortex dataset
data(neocortex)

## Plot the tree
plot(ladderize(phy), cex = 0.6)
```


Data Prep
```{r}
ruminant.trdata <- make.treedata(phy, neocortex,name_column="species")
#ruminant.trdata<-mutate(ruminant.trdata,me.log_ant_vol=ruminant.trdata$dat$log_vol_var_est/ruminant.trdata$dat$n)
#ruminant.trdata<-mutate(ruminant.trdata,me.log_psl=ruminant.trdata$dat$log_psl_var_est/ruminant.trdata$dat$n)

ruminant.trdata<-filter(ruminant.trdata,!(is.na(neocortex_area_mm2_log_mean)) & !(is.na(brain_mass_g_log_mean)))
ruminant.trdata<-filter(ruminant.trdata,!(is.na(neocortex_se_squared)) & !(is.na(brain_se_squared)))
ruminant.trdata

#Mean Standardized
ruminant.trdata$dat$braincentered<-ruminant.trdata$dat$brain_mass_g_log_mean-mean(ruminant.trdata$dat$brain_mass_g_log_mean)




```

Rescale Tree to Height =1
```{r}
l.tree<-max(branching.times(ruminant.trdata$phy))
ruminant.trdata$phy$edge.length<-ruminant.trdata$phy$edge.length/l.tree ## rescale tree to height 1
max(branching.times(ruminant.trdata$phy))

```

Slouch Results for Comparison
Adaptation model
```{r}

#OU Model of Evolution
slouch.OU<-slouch.fit(phy = ruminant.trdata$phy,
                              species = ruminant.trdata$phy$tip.label,
                              response = ruminant.trdata$dat$neocortex_area_mm2_log_mean,
                              random.cov = ruminant.trdata$dat$braincentered,
                              mv.response = ruminant.trdata$dat$neocortex_se_squared,
                              mv.random.cov = ruminant.trdata$dat$brain_se_squared,
                              hl_values = seq(0.00001, 0.2, length.out = 50),
                              vy_values = seq(0.00001, 0.1, length.out = 50),
                              hillclimb = TRUE,convergence = 150,
                              lower = c(0.00001, 0.00001)

                       )
summary(slouch.OU)
```
Constraint Model
```{r}
#OU Model of Evolution
slouch.OU<-slouch.fit(phy = ruminant.trdata$phy,
                              species = ruminant.trdata$phy$tip.label,
                              response = ruminant.trdata$dat$neocortex_area_mm2_log_mean,
                              direct.cov = ruminant.trdata$dat$braincentered,
                              #mv.response = ruminant.trdata$dat$neocortex_se_squared,
                              #mv.direct.cov = ruminant.trdata$dat$brain_se_squared,
                              hl_values = seq(0.00001, , length.out = 50),
                              vy_values = seq(0.00001, 0.5, length.out = 50),
                              hillclimb = TRUE,convergence = 150,
                              lower = c(0.00001, 0.00001)

                       )
summary(slouch.OU)
```

Get bias correct coefficients
```{r}
slouch.OU$beta_primary$coefficients_bias_corr

```

Running Blouch Data Setup Function - 1st trait is adapting to 2

Here we will create a R object called stan_data which has all the data we are sending to Blouch in the Stan format. This includes a list called dist.values, which provides parameter values of the distributions we are going to be using for our runs. Initially these values can be any that seem reasonable - below is code to zoom in on the parameters that best fit your data.

First we will run Blouch without including Measurement Error

```{r}
par(mfrow = c(1,1))

#source("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Stan Functions/blouch v1/Blouch Setup Files/blouchOU.setup.v1.R")

source("/Users/markgrabowski/Documents/Academic/Research/Current Projects/blouch/R/R Functions/Blouch Setup Files/blouchOU.setup.v1.R")

#No Measurement Error
names.traits<-c("neocortex_area_mm2_log_mean","braincentered",NA,NA)
#Include Measurement Error
#names.traits<-c("neocortex_area_mm2_log_mean","braincentered","neocortex_se_squared","brain_se_squared")


dist.values<-list(mean_log=1.25, sd_log=1.25,intercept_sd=0.5, slope_sd = 0.4,sigma2_y_scale = 0.1)

#Data must be logged before entry into blouchOU.setup
#names.traits = c(response, predictor, me.response, me.predictor)
stan_data<-blouchOU.setup.v1(ruminant.trdata,names.traits,dist.values)

stan_constraint_data<-stan_data[[1]]
stan_adaptive_data<-stan_data[[2]]

```


# Explore Priors: Slope and intercept
First lets look at how our priors for the intercept and slope look given the dispersion of the data
```{r}
library(ggsci)

intercept_test<-rnorm(100,stan_adaptive_data$ols_intercept,0.5)
#slope_test<-rnorm(100,ols.slope,0.5)
slope_test<-rnorm(100,stan_adaptive_data$ols_slope,1.0)

slope.prior.plot<-ggplot(data=ruminant.trdata$dat,aes(y=neocortex_area_mm2_log_mean,x=braincentered))+
  geom_point()+
  geom_abline(intercept=intercept_test,slope=slope_test,alpha=0.25)+
  theme_bw()+
  ggtitle("Priors for Intercept and Slope")+
  ylab("log Neocortex Area (mm2)") + xlab("log Brain Mass (g)")+
  scale_color_npg()

slope.prior.plot

```
Lets use a stronger prior
```{r}
intercept_test<-rnorm(100,stan_adaptive_data$ols_intercept,0.5)
#slope_test<-rnorm(100,ols.slope,0.5)
slope_test<-rnorm(100,stan_adaptive_data$ols_slope,0.4)

slope.prior.plot<-ggplot(data=ruminant.trdata$dat,aes(y=neocortex_area_mm2_log_mean,x=braincentered))+
  geom_point()+
  geom_abline(intercept=intercept_test,slope=slope_test,alpha=0.25)+
  theme_bw()+
  ggtitle("Priors for Intercept and Slope")+
  ylab("log Neocortex Area (mm2)") + xlab("log Brain Mass (g)")+
  scale_color_npg()

slope.prior.plot
```
This looks pretty good.

# Explore Priors: Half-life
Since our tree is unit length = 1, and the original phylogeny is ~27 Ma, we would like our half-life prior to be allow for very quick adaotation (e.g < 1 Ma, which equals < 0.04 in tree units), and very slow adaptation (e.g. > 27 Ma, which equals 1 in tree units). Thus, we will the 10% quantile of the distrubution at 0.04 and 90% at 1.

We can explore how changing our mean-log and sd-log priors effect our distibution as below. The values 1.25 and 1.25 for these two parameters are sufficient for this example analysis, but given your own data all parameters should be explored and the best values determined.

```{r}
###########################################
#Log-normal prior for half-life - based on alpha
par.alpha <- list(meanlog=1.25, sdlog=1.25) 

samp <- rlnorm(10000, mean=par.alpha$meanlog, sd=par.alpha$sdlog)
samp<-samp[samp>=0]

hist(samp, breaks=10000, main="Prior density of alpha",xlim=c(0,3))
#abline(v=(c(log(2)/0.07142857,log(2)/1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
min(samp)
max(samp)
log(2)/min(samp)
log(2)/max(samp)

quantiles <- c(0, 0.01, 0.025,0.10, 0.25, 0.5, 0.75,0.90,0.95, 0.975, 0.99, 1)
#hls <- rlnorm(10000, meanlog=log(2)/par.alpha$meanlog, sdlog=log(2)/par.alpha$sdlog)
#hls<-hls[hls>=0]
qs <- quantile(log(2)/samp, quantiles) ## Use 'alfs' and math to calculate the quantiles of phylogenetic half-life
round(qs, 2)

hist((log(2)/samp), breaks=10000, main="Prior density of half-life",xlim=c(0,3))
abline(v=(c(0.07142857,1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
########################################
```
Sigma2_y Prior
```{r}
library(extraDistr)
###########################################
#Normal - based on alpha
par.sigma2y <- list(sigma=0.1)

samp <- rhcauchy(10000, sigma=par.sigma2y$sigma)

hist(samp, breaks=10000, main="Prior density of Sigma2y",xlim=c(0,3))
#abline(v=(c(log(2)/0.07142857,log(2)/1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
min(samp)
max(samp)
log(2)/min(samp)
log(2)/max(samp)

quantiles <- c(0, 0.01, 0.025,0.10, 0.25, 0.5, 0.75, 0.90, 0.975, 0.99, 1)
#hls <- rlnorm(10000, meanlog=log(2)/par.alpha$meanlog, sdlog=log(2)/par.alpha$sdlog)
#hls<-hls[hls>=0]
qs <- quantile(samp, quantiles) ## Use 'alfs' and math to calculate the quantiles of phylogenetic half-life
round(qs, 2)

hist(samp/(2*2), breaks=10000, main="Prior density of Vy",xlim=c(0,3))
#abline(v=(c(0.07142857,1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
########################################

```


```{r}
library(extraDistr)
###########################################
#Normal - based on alpha
par.sigma2y <- list(sigma=1.0)

samp <- rhcauchy(10000, sigma=par.sigma2y$sigma)

hist(samp, breaks=10000, main="Prior density of Sigma2y",xlim=c(0,3))
#abline(v=(c(log(2)/0.07142857,log(2)/1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
min(samp)
max(samp)
log(2)/min(samp)
log(2)/max(samp)

quantiles <- c(0, 0.01, 0.025,0.10, 0.25, 0.5, 0.75, 0.90, 0.975, 0.99, 1)
#hls <- rlnorm(10000, meanlog=log(2)/par.alpha$meanlog, sdlog=log(2)/par.alpha$sdlog)
#hls<-hls[hls>=0]
qs <- quantile(samp, quantiles) ## Use 'alfs' and math to calculate the quantiles of phylogenetic half-life
round(qs, 2)

hist(samp/(2*2), breaks=10000, main="Prior density of Vy",xlim=c(0,3))
#abline(v=(c(0.07142857,1)), col="red", lwd=2, lty=2) #Lines for 1 Ma and length of tree (14 Ma) - 
########################################

```
Now that we have formatted our data and supplied reasonable priors for the various distributions, we can now run Blouch using the R package Stan. Stan (Carpenter et al., 2017),  allows estimation of Bayesian models using Markov chain Monte Carlo (MCMC) methods based on the Hamilton Monte Carlo sampler.

First lets  we fit a model to measure phylogenetic effect in both neocortex size and overall brain size. This would be using the Blouch function blouch_OU1_v1.stan, which is written in the Stan language.


```{r}




```


# Direct Effect Models
Blouch implements the model of constrained evolution (Hansen & Bartoszek, 2012) previously implemented in Grabowski et al. (2016), which can be used to test for allometric constraints.

Here we run this model using 2 chains and 4000 iterations per chain.
```{r}
setwd("/Users/markgrabowski/Documents/Academic/Research/Current Projects/blouch/R/R Functions/Blouch Functions")
stanc("/Users/markgrabowski/Documents/Academic/Research/Current Projects/blouch/R/R Functions/Blouch Functions/blouchOU_v1.stan")

stan_model <- stan_model("blouchOU_v1.stan")

fit.direct<- rstan::sampling(object = stan_model,data = stan_constraint_data,chains = 2,iter = 4000,control=list(adapt_delta=0.95))

#Lets look at the parameter estimates
print(fit.direct,pars = c("a","hl","alpha","beta","vy","r_squared","sigma2_y"))

#For downstream analysis and plots
ext.fit.direct <- rstan::extract(fit.direct)

```

Trace and Density Plots for estimated parameters
```{r}
par(mfrow = c(1,3))

traceplot(fit.direct,c("a","hl","alpha","beta[1]","vy","sigma2_y"))
stan_dens(fit.direct,c("a","hl","alpha","beta[1]","vy","sigma2_y"))
#3X8
```

#Adaptive Model
Blouch also implements the model of adaptive evolution introduced by Hansen et al. (2008). Here the response variable evolves according to an Ornstein-Uhlenbeck process towards an optimal state that is modeled as a function of the predictor variable.

Here the code is mostly the same, but the data type sent to Stan is a different format from the stan_constraint_data above.

```{r}
setwd("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1")
stanc("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1/blouchOU_test.stan")
stan_model <- stan_model("blouchOU_test.stan")

fit.adaptive<- rstan::sampling(object = stan_model,data = stan_adaptive_data,chains = 2,iter = 4000,control=list(adapt_delta=0.95))

print(fit.adaptive,pars = c("a","hl","alpha","beta","vy","r_squared","sigma2_y"))


```

```{r}
par(mfrow = c(1,3))

traceplot(fit.adaptive,c("a","hl","alpha","beta","vy","sigma2_y"))
stan_dens(fit.adaptive,c("a","hl","alpha","beta","vy","sigma2_y"))
#3X8
```

# Model Comparison using Bayes Factors
While using a Direct Effect or Adaptive model should be driven by the biological hypotheses being tested, it is simple to compare between different models using Bayes Factors. Here we use the bridgesampling R package.

```{r}
library(bridgesampling)

lml.fit.direct<-bridge_sampler(fit.direct,silent=TRUE)
lml.fit.adaptive<-bridge_sampler(fit.adaptive,silent=TRUE)
BF_att <- bridgesampling::bf(lml.fit.direct, lml.fit.adaptive)
BF_att

```


## Estimated Bayes factor in favor of lml_pupil over lml_pupil_null: 0.99924

We find that the data is 0.999 more likely under a model that assumes XX


# Brownian Model
Blouch can also fit a Brownian motion model to the data, which can then be compared to the other models using Bayes Factors. Note that while this is possible with Blouch, it is assuming your data follows this model of evolution, rather than testing for it using the Direct Effect or Adaptive models above. 

```{r}
setwd("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1")
stanc("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1/blouchBM_v1.stan")
stan_model <- stan_model("blouchBM_v1.stan")

fit.BM.hc<- rstan::sampling(object = stan_model,data = stan_constraint_data,chains = 2,iter = 4000,control=list(adapt_delta=0.95))

print(fit.BM.hc,pars = c("alpha","beta","r_squared","sigma2_y"))

```



BM Model - with sigma2y ~ uniform
```{r}
setwd("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1")
stanc("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1/blouchBM_v1.stan")
stan_model <- stan_model("blouchBM_v1.stan")

fit.BM.uni<- rstan::sampling(object = stan_model,data = stan_constraint_data,chains = 2,iter = 4000,control=list(adapt_delta=0.95))

print(fit.BM.uni,pars = c("alpha","beta","r_squared","sigma2_y"))

```


Model Comparison using Bayes Factors
```{r}
library(bridgesampling)
lml.fit.BM.hc<-bridge_sampler(fit.BM.hc,silent=TRUE)
lml.fit.BM.uni<-bridge_sampler(fit.BM.uni,silent=TRUE)
#lml.fit.hc.direct<-bridge_sampler(fit.hc.direct,silent=TRUE)
#lml.fit.BM<-bridge_sampler(fit.BM,silent=TRUE)
#BF_att <- bridgesampling::bf(lml.fit.direct, lml.fit.BM)
BF_att <- bridgesampling::bf(lml.fit.BM.uni, lml.fit.BM.hc)
BF_att

```

Direct vs. BM Model Comparison using BF
```{r}
library(bridgesampling)
lml.fit.uni.direct<-bridge_sampler(fit.uni.direct,silent=TRUE)
lml.fit.BM.uni<-bridge_sampler(fit.BM.uni,silent=TRUE)

BF_att <- bridgesampling::bf(lml.fit.uni.direct, lml.fit.BM.uni)
BF_att

```






Make plots for Figure
```{r}
library(ggsci)
library(ggplot2)

```

Fig S1
```{r}
old.par <- par(mar = c(0, 0, 0, 0))
par(old.par)


ggplot(ruminant.trdata$dat,aes(y=log_ant_vol,x=log_psl))+
  geom_abline(intercept=mean(posterior.fit.uni.direct$alpha),slope = mean(posterior.fit.uni.direct$beta),lty=1)+
  geom_abline(intercept=-1.16,slope = 5.89,lty=2)+

  geom_point(aes(color=Tribe),size=2.0,alpha=0.8)+
  theme_bw()+
  theme(legend.position="bottom")+
  ylab("log Antler Volume (l)") + xlab("log Posterior Skull Length (mm)")+
  scale_color_npg()
 
#5.25 X 5

```





Rerun for predicting Irish Elk Antler length
Data Prep
```{r}
#cervid.tree<-read.nexus("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Data/Antler Dataset/cervidae_renamed.tre")
cervid.tree<-read.nexus("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Data/Antler Dataset/cervidae_renamed.tre")

#cervid.dataset<-read.csv("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Data/Antler Dataset/deer_mean_dat.csv")

cervid.dataset<-read.csv("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Data/Antler Dataset/deer_mean_dat.csv")



#Remove Muntiacus_atherodes, Elaphodus_cephalophus - rudamentary and female Rangifer. 
cervid.dataset<-filter(cervid.dataset,Genus_Species != "Sinomegaloceros_yabei" & ! Genus_Species =="Alces_alces_gigas"  & ! Genus_Species == "Muntiacus_truongsonensis" & ! Genus_Species ==  "Mazama_temama"& ! Genus_Species ==  "Muntiacus_feae" & ! Genus_Species ==  "Muntiacus_atherodes" & ! Genus_Species ==  "Elaphodus_cephalophus")


ruminant.trdata <- make.treedata(cervid.tree, cervid.dataset,name_column="Genus_Species")
ruminant.trdata<-mutate(ruminant.trdata,me.log_ant_vol=ruminant.trdata$dat$log_vol_var_est/ruminant.trdata$dat$n)
ruminant.trdata<-mutate(ruminant.trdata,me.log_psl=ruminant.trdata$dat$log_psl_var_est/ruminant.trdata$dat$n)

#names.traits<-c("log_ant_vol","log_psl",NA,NA)

names.traits<-c("log_ant_vol","log_psl","me.log_ant_vol","me.log_psl")
ruminant.trdata<-filter(ruminant.trdata,!(is.na(log_ant_vol)) & !(is.na(log_psl)))
ruminant.trdata<-filter(ruminant.trdata,!(is.na(me.log_ant_vol)) & !(is.na(me.log_psl)))

#Only for reduced Cervini analysis
#ruminant.trdata<-filter(ruminant.trdata, (Tribe == "Cervini")) #Only non-fossil species

cervid.ext.trdata<-filter(ruminant.trdata, (Status == "Extant")) #Only non-fossil species

#Mean Standardized
ruminant.trdata$dat$log_psl<-ruminant.trdata$dat$log_psl-mean(ruminant.trdata$dat$log_psl)
cervid.ext.trdata$dat$log_psl<-cervid.ext.trdata$dat$log_psl-mean(cervid.ext.trdata$dat$log_psl)


```

Rescale Tree to Height =1
```{r}
l.tree<-max(branching.times(ruminant.trdata$phy))
ruminant.trdata$phy$edge.length<-ruminant.trdata$phy$edge.length/l.tree ## rescale tree to height 1
max(branching.times(ruminant.trdata$phy))

l.tree<-max(branching.times(cervid.ext.trdata$phy))
cervid.ext.trdata$phy$edge.length<-cervid.ext.trdata$phy$edge.length/l.tree ## rescale tree to height 1
max(branching.times(cervid.ext.trdata$phy))


```


Running Blouch Data Setup Function - 1st trait is adapting to 2
```{r}
#source("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1/Blouch Setup Files/blouchOUPredict.setup.v1.R")

source("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Stan Functions/blouch v1/Blouch Setup Files/blouchOUPredict.setup.v1.R")

#Data must be logged before entry into blouch.setup
#names.traits = c(response, predictor, me.response, me.predictor) - classical = 0 for inverse regression
stan_data<-blouchOUPredict.setup.v1(cervid.ext.trdata,ruminant.trdata,names.traits,classical=0)

stan_constraint_data<-stan_data[[1]]
stan_adaptive_data<-stan_data[[2]]

```

Constraint Model
```{r}
#setwd("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1")
#stanc("/Users/markgrabowski/Documents/Academic/Research/Current Projects/Blouch project/Stan Functions/blouch v1/blouchOUPredict_v1.stan")

setwd("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Stan Functions/blouch v1")
#stanc("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Stan Functions/blouch v1/blouchOUPredict_v1.stan")

stanc("/Users/markgrabowski/Google Drive/Shared with Macbook/Current Projects/Blouch project/Stan Functions/blouch v1/blouchOUPredict_test.stan")

#stan_model <- stan_model("blouchOUPredict_v1.stan")
stan_model <- stan_model("blouchOUPredict_test.stan")

#fit.direct<- stan(file = stan_model,data = stan_constraint_data,chains = 1,iter = 400,control=list(adapt_delta=0.95))
fit.fos.direct<- rstan::sampling(object = stan_model,data = stan_constraint_data,chains = 2,iter = 4000,control=list(adapt_delta=0.95),save_warmup=FALSE)

print(fit.fos.direct,pars = c("a","hl","alpha","beta","vy","r_squared","sigma2_y","RMSE","RMSE_mu","Y_pred_fos_means"))
posterior.fit.fos.direct <- rstan::extract(fit.fos.direct)

```


```{r}
par(mfrow = c(1,3))
  
traceplot(fit.fos.direct,c("a","hl","alpha","beta","vy","sigma2_y"))
stan_dens(fit.fos.direct,c("a","hl","alpha","beta","vy","sigma2_y"))
#3 X 8
```


Make plots for Figure
```{r}
library(ggsci)
library(ggplot2)
library(plotly)

```

Fig. 1
```{r}
cervid.fos.plot<-ggplot(ruminant.trdata$dat,aes(y=log_ant_vol,x=log_psl))+
  geom_abline(intercept=mean(posterior.fit.fos.direct$alpha),slope = mean(posterior.fit.fos.direct$beta),lty=1)+
  #geom_abline(intercept=-15.123391,slope = 5.932,lty=2)+
  #geom_abline(intercept=-11.8719729343,slope = 4.86,lty=2)+ #Cervini slope going through Dama dama - from Tsuboi et al.
  #geom_abline(intercept=-11.48,slope = 4.70,lty=3)+ #Cervini slope going through Dama dama - from Blouch
  #geom_point(aes(y= 3.28,x=3.089545121),size=2.0,alpha=0.8)+
  geom_point(aes(y= 3.28,x=0.7373661),size=2.0,alpha=0.8)+
  geom_point(aes(color=Tribe),size=2.0,alpha=0.8)+
  theme_bw()+
  #theme(legend.position="bottom")+
  ylab("log Antler Volume (l)") + xlab("log Posterior Skull Length (mm)")+
  scale_color_npg()
 

cervid.fos.plot
#ggplotly()
#5.25 X 5
#5 X 7
```
Plot including predictions for extant species
Fig. 2b
SI HW Prediction Means - 5X5 pdf
```{r}
old.par <- par(mar = c(0, 0, 0, 0))
par(old.par)


fos.index<-which(ruminant.trdata$dat$Status=="Extinct")
print(paste("Fossil Species #",fos.index))
extant.index<-which(ruminant.trdata$dat$Status=="Extant")

antler.predictions<-apply(posterior.fit.fos.direct$Y_pred_fos_means,2,mean)
antler.predictions.extant<-apply(posterior.fit.fos.direct$Y_pred_extant_means,2,mean)

extant.data<-data.frame(Genus_Species = ruminant.trdata$phy$tip.label[-fos.index],log_AV = ruminant.trdata$dat$log_ant_vol[-fos.index],log_AV_predictions = antler.predictions.extant,log_psl = ruminant.trdata$dat$log_psl[-fos.index],Status="Extant")

fos.predictions<-data.frame(Genus_Species = ruminant.trdata$phy$tip.label[fos.index],log_AV = NA, log_AV_predictions = antler.predictions,log_psl=ruminant.trdata$dat$log_psl[fos.index],Status="Extinct")
         
merged.data<-rbind(extant.data,fos.predictions)                   

antler.complete.plot<-ggplot(merged.data,aes(x=log_psl))+
geom_point(aes(y=log_AV),size=2.0,alpha=0.4)+
geom_point(aes(y=log_AV_predictions,color=Status),size=2.5,alpha=0.8)+
geom_abline(intercept=mean(posterior.fit.fos.direct$alpha),slope = mean(posterior.fit.fos.direct$beta),lty=2)+
theme_bw()+
theme(legend.position="bottom")+ #5X5
xlab("log Posterior Skull Length (mm)")+
  ylab("log Antler Volume (l)")

#+theme(legend. position = "none")
antler.complete.plot+scale_color_aaas()
#Export 5.25X5 PDF

```
